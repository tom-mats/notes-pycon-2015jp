# TORNAD/ELASTIC Searchを用いた大量ツイートのリアルタイム関連文書判定

## アジェンタ

* Elasticsearchに置ける日本語処理
* Pythonを使ってscale outする仕組み

## 背景

* 日本語文章の関連文書分類
  * 分類分け
  + タグ付け
  + 機械学習を用いた取り組みが増えている
+ 機械学習について
  + まとまりのある文章(マニュアルとかか)には向いている
  * ツイッターのように短く散文な文章には向かない

### その他の判定方法

* 短文の関連文書判定
  + 正規表現をつかうのがstraight forward
    * 正確ではある
    * 自動化は無理
    * いちいち書くのは大変である．
    * ワイルドカードを間違えると一気に意味が変わってしまう

## アイディア

短文 -> Search Engine -> 分類

### Search Engine

>  一定の基準で分類(スコア?適合率?)
>> -> Search engine に何を使うかが需要
>> Elasticsearch

### Elasticsearch

* 分散型Restful
* アナライザが豊富
* 検索結果のスコアリングが可能

### 今回の例

テレビ番組に関するツイート
EPG,番組名，出演者，放送時間

## どうやってマッチさせるか

+ 一番の問題は日本語
  * 形態素解析をいかにうまく行うか

### Elastic searchと日本語

+ 形態素解析
  + kuromoji plugin
  * Mecab
  * N-Gram

+ kuromoji
  + 解析してくれるがノイズが多い
+ Mecab
  + 辞書の制度に依存
* N-Gram
  + 2-Gramは制度がいいけど，インデックスが100GBとデータが膨大
  * 3-Gramだと2文字の単語に一致しなくなる

### ツイートの解析

+ ツイートの解析をいかにクレンジングして，意味のキーワードを正しく取り出せるか

* Macabは名刺を正しく取り出せる
  * クレンジングにMecabを使用する

### Macab

+ ユーザ辞書の作成(Wikipedia，番組表)
  * うまく調整しないと意味のないキーワードが生成されてしまう
  * mecab dic over drive
* 品質連結次第で未知語も意味ある単語に
  + 言選ロジック

# Elastcのブースト

* 重要な単語は2回投げてやる

# 実装

+ Base
 Tornado with Elasticsearch
* DB
  Redis
  MySQL
  Elasticsearch
+ 判定ロジックさえ増やしてあげれば大量のデータを解析できる
